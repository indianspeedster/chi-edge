{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using edge devices for CPU-based inference"
   ],
   "id": "36ca61a6-f71f-4a3f-a0d4-abf51c5f3d4c"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine learning models are most often trained in the “cloud”, on powerful centralized servers with specialized resources (like GPU acceleration) for training machine learning models.\n",
    "\n",
    "However, for a variety of reasons including privacy, latency, and network connectivity or bandwidth constraints, it is often preferable to *use* these models (i.e. do inference) at “edge” devices located wherever the input data is/where the model’s prediction is going to be used.\n",
    "\n",
    "These edge devices are less powerful and typically lack any special acceleration, so the inference time (the time from when the input is fed to the model, until the model outputs its prediction) may not be as fast as it would be on a cloud server - but we avoid having to send the input data to the cloud and then sending the prediction back."
   ],
   "id": "d8b67af1-22ea-43e4-bf4c-a0c46ae3becb"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook assumes you already have a “lease” available for a Raspberry Pi device on the CHI@Edge testbed. Then, it will show you how to:\n",
    "\n",
    "-   launch a “container” on that device\n",
    "-   attach an IP address to the container, so that you can access it over SSH\n",
    "-   transfer files to and from the container\n",
    "-   use a pre-trained image classification model to do inference on the edge device\n",
    "-   delete the container"
   ],
   "id": "f6907a06-383d-489b-92c3-45cb61f56b3c"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launch a container on an edge device\n",
    "\n",
    "We will start by preparing our environment in this notebook, then launching a container on an edge device using our pre-existing lease."
   ],
   "id": "629ae3d6-2dc3-4ebc-9a64-7aa1de38e6ee"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we load some required libraries:"
   ],
   "id": "6658075f-cc11-4634-85e6-3498c3e2dce1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chi\n",
    "from chi import container\n",
    "from chi import lease\n",
    "import datetime\n",
    "import os"
   ],
   "id": "e0ffbdf2-8c92-4adf-822d-de437f6713c6"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We indicate that we’re going to use the CHI@Edge site. We also need to specify the name of the Chameleon “project” that this experiment is part of. The project name will have the format “CHI-XXXXXX”, where the last part is a 6-digit number, and you can find it on your [user dashboard](https://chameleoncloud.org/user/dashboard/).\n",
    "\n",
    "In the cell below, replace the project ID with your *own* project ID, then run the cell."
   ],
   "id": "5e405891-ed9c-4dd0-8087-39a039ac6f73"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi.use_site(\"CHI@Edge\")\n",
    "chi.set(\"project_name\", \"CHI-XXXXXX\")"
   ],
   "id": "9edae9a8-05a1-4fd0-8746-17e8539726d9"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we’ll specify the lease ID. This notebook assumes you already have a “least” for a Raspberry Pi device on CHI@Edge. To get the ID of this lease,\n",
    "\n",
    "-   Vist the CHI@Edge [“reservations” page](https://chi.edge.chameleoncloud.org/project/leases/).\n",
    "-   Click on the lease name.\n",
    "-   On the following page, look for the value next to the word “Id” in the “Lease” section.\n",
    "\n",
    "Fill in the lease ID inside the quotation marks in the following cell, then run the cell."
   ],
   "id": "f5b698ea-05e3-4447-b167-ba754245876b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lease_id =\"xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\""
   ],
   "id": "7645d1b0-d065-454f-b85e-20164e47278b"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are ready to launch a container!\n",
    "\n",
    "-   **Container** : A container is like a logical “box” that holds everything needed to run an application. It includes the application itself, along with all the necessary prerequisite software, files, and settings it needs to work properly.\n",
    "-   **Image** : An image is like a pre-packaged “starting point” for a container. In this example, we’re going to run a machine learning application written in Python, so we will use the `python:3.9-slim` image as a starting point for our container. This is a lightweight installation of the Debian Linux operating system with Python pre-installed.\n",
    "\n",
    "When we create the container, we could also specify some additional arguments:\n",
    "\n",
    "-   `workdir`: the “working directory” - location in the container’s filesystem from which any commands we specify will run.\n",
    "-   `exposed_ports`: if we run any applications inside the container that need to accept incoming requests from a network, we will need to export a “port” number for those incoming requests. Any requests to that port number will be forwarded to this container.\n",
    "-   `command`: if we want to execute a specific command immediately on starting the container, we can specify that as well.\n",
    "\n",
    "For this particular experiment, we’ll specify that port 22 - which is used for SSH access - should be exposed."
   ],
   "id": "3dd2d7d3-b2c6-469e-a39d-f4727d9033d2"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we’ll specify the name for our container - we’ll include our username and the experiment name in the container name, so that it will be easy to identify our container in the CHI@Edge web interface."
   ],
   "id": "0c3cebc2-216b-4a05-8b04-a8a691a8de1b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = os.environ.get(\"USER\")\n",
    "expname = \"edge-cpu\"\n",
    "# set a name for the container\n",
    "# Note that underscore characters _ are not allowed - we replace each _ with a -\n",
    "container_name = f\"{username}-{expname}\".replace(\"_\",\"-\")"
   ],
   "id": "eba2c805-fcb8-4d4f-8a8c-377df877ac5a"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can create the container!"
   ],
   "id": "d3e60448-08fa-47f7-a2ca-1ef7eb3a7d3e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    my_container = container.create_container(\n",
    "        container_name,\n",
    "        image=\"python:3.9-slim\",\n",
    "        reservation_id=lease.get_device_reservation(lease_id),\n",
    "        exposed_ports=[\"22\"],\n",
    "        platform_version=2,\n",
    "    )\n",
    "    # wait until container is ready to use\n",
    "    my_container.wait_for_active()\n",
    "except RuntimeError as ex:\n",
    "    print(ex)\n",
    "    print(f\"Please stop and/or delete {container_name} and try again\")\n",
    "else:\n",
    "    print(f\"Successfully created container: {container_name}!\")"
   ],
   "id": "0bafe4ab-af86-4407-b202-2a4d272568ae"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the container is created, you should be able to see it and monitor its status on the [CHI@Edge web interface](https://chi.edge.chameleoncloud.org/project/container/containers). (If there was any problem while creating the container, you can also forcefully delete the container from the interface, in order to be able to try again.)"
   ],
   "id": "f35233b8-09f5-4822-9f59-c2f7ee3fbd09"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attach an address and access your container over SSH"
   ],
   "id": "80c2961f-0619-49b3-9426-5f66380cb91c"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as with a conventional “server” on Chameleon, we can attach an address to our container, then use SSH to access its terminal.\n",
    "\n",
    "First, we’ll attach an address:"
   ],
   "id": "2523a9b9-c5f3-4c6d-87e9-5dfa5558ac93"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "public_ip = container.associate_floating_ip(my_container.uuid)```"
   ],
   "id": "6dab978e-180c-4705-ba22-0aab11bc2d6a"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we need to install an SSH server on the container - it is not pre-installed on the image we selected. We can use the `container.execute()` function to run commands inside the container, in order to install the SSH server."
   ],
   "id": "c29a3ebf-09ae-44de-8d37-f5c7b512b76a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "container.execute(my_container.uuid, 'apt update; apt -y install openssh-server')"
   ],
   "id": "73287067-09b9-4c1d-9c31-cf09426f22eb"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is one more necessary step before we can access the container over SSH - we need to make sure our key is installed on the container. Here, we will install the key from the Jupyter environment."
   ],
   "id": "a452785a-9734-4474-b31b-6d0327816350"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can open a terminal in the Jupyter interface to access the container over SSH, using the SSH command that is printed by the following cell:"
   ],
   "id": "37303b86-3cd8-40c1-960f-e87df09bb4f1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ssh root@%s\" % public_ip)"
   ],
   "id": "61c73935-cefa-46ea-8fbb-bf25e115cf45"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interacting with the container\n",
    "\n",
    "Just like you ssh into a virtual machine and access that machine, you also can access the container by running terminal commands via container.execute() function."
   ],
   "id": "9a2a628d-aa12-4cf0-86ee-59fafc7bced6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "echo Hello\n",
      "Hello"
     ]
    }
   ],
   "source": [
    "cmd = 'echo Hello'\n",
    "print(cmd)\n",
    "\n",
    "print(container.execute(my_container.uuid, cmd)[\"output\"])"
   ],
   "id": "1be467fa-760b-434d-a754-4ec8d832c84e"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfering files to and from the container\n",
    "\n",
    "-   To upload files to container we use `container.upload(container_ref: 'str', source: 'str', dest: 'str')` function.\n",
    "-   to download files from container to our local we use `container.download(container_ref: 'str', source: 'str', dest: 'str')` function."
   ],
   "id": "6e2f0936-9677-427a-9224-e753a2614a96"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Files uploaded!"
     ]
    }
   ],
   "source": [
    "container.upload(my_container.uuid, \"./python_code\", \"/var/www/html\")\n",
    "#The code will be uploading some files which we will be going to use for our american sign language classification model\n",
    "print(\"Files uploaded!\")"
   ],
   "id": "3a7690a7-ddef-465d-bdbe-692a7adf200f"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an image classification model using tflite\n",
    "\n",
    "The folder which we previously uploaded contains:\n",
    "\n",
    "-   model.py (The python file which contains all the code to run the model)\n",
    "-   model.tflite (The tensorflow lite machine learning model for edge devices)\n",
    "-   image.png (This image which is going to be used to make prediction)\n",
    "-   Requirments.txt (Requirements file which is used to install all the requirements for our machine learning model)"
   ],
   "id": "55816c78-7455-434c-9901-70807e79e742"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing the required libraries\n",
    "\n",
    "We will be installing some of the libraries that we are going to need for our ml model."
   ],
   "id": "5ee3ea37-e39f-41ae-97da-45c033fd1eff"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "pip install -r requirements.txt\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/site-packages (from -r requirements.txt (line 1)) (1.24.4)\n",
      "Requirement already satisfied: tflite-runtime in /usr/local/lib/python3.8/site-packages (from -r requirements.txt (line 2)) (2.13.0)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.8/site-packages (from -r requirements.txt (line 3)) (10.0.0)"
     ]
    }
   ],
   "source": [
    "cmd = \"pip install -r requirements.txt\"\n",
    "print(cmd)\n",
    "print(container.execute(my_container.uuid, cmd)[\"output\"])"
   ],
   "id": "a6c4ec8c-18ed-47d4-b087-53f6d049aed5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "pip list\n",
      "Package        Version\n",
      "-------------- -------\n",
      "numpy          1.24.4\n",
      "Pillow         10.0.0\n",
      "pip            23.0.1\n",
      "setuptools     57.5.0\n",
      "tflite-runtime 2.13.0\n",
      "wheel          0.40.0\n",
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1.2\n",
      "[notice] To update, run: pip install --upgrade pip"
     ]
    }
   ],
   "source": [
    "cmd = \"pip list\"\n",
    "print(cmd)\n",
    "print(container.execute(my_container.uuid, cmd)[\"output\"])"
   ],
   "id": "be58b6b8-c70d-465b-b42d-4aa031b94e28"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the model"
   ],
   "id": "a1458cf8-099d-4bd9-8f91-c1d6e414abd8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "python model.py\n",
      "0.580392: fig\n",
      "0.568627: Granny Smith\n",
      "0.549020: spaghetti squash"
     ]
    }
   ],
   "source": [
    "cmd = \"python model.py\"\n",
    "print(cmd)\n",
    "print(container.execute(my_container.uuid, cmd)[\"output\"])"
   ],
   "id": "e85128b9-5952-4c6b-a7e0-4f34887bf205"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [],
   "id": "562dbc52-a886-499f-a877-ad987b95921a"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
